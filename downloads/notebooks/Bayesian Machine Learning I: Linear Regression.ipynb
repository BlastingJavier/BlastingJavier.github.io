{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Programming\n",
    "\n",
    "Existe una guerra centenaria en el ambito de la estadistica, por un lado la estadistica frecuentista y la estadistica bayesiana, ambas ramas pretender ofrecer inferencias, test de robustez y analisis cuantitativo y cualitativo de los datos, pero su filosofia es totalmente diferente.\n",
    "\n",
    "Cuando tenemos un acercamiento frecuentista a una serie de mediciones a menudo lo que estimamos son los parametros a partir de unos datos, pero estos parametros $\\theta$ son estaticos, es decir unicos para unos datos $X$.\n",
    "\n",
    "Por el contrario, en el acercamiento bayesiano tenemos en cuenta la fragilidad de la inferencia y los datos, y tomamos $\\theta$ como una variable aleatoria que debe de ser cuantificada y unos datos estaticos $X$.\n",
    "\n",
    "\n",
    "El modelaje bayesiano ha sido criticado durante buena parte del siglo XX, la falta de medios y el contexto historico han hecho ganar puntos a los frecuentistas.\n",
    "\n",
    "Sin embargo, metodos avanzados de computo y su facilidad de utilizacion han impulsado de nuevo el campo, este impulso nacio por la creacion de los metodos de \"sampling inference\" como MCMC (Markov chain Montecarlo) y sus variantes, estos metodos permiten hacer inferencia bayesiana aproximada.\n",
    "\n",
    "Veamos un ejemplo:\n",
    "\n",
    "Tenemos un problema de inferencia bayesiana aplicada al Machine learning del siguiente tipo:\n",
    "$$ p(y|X, Y_{train}, X_{train}) = \\int {p(y|X, w).p(w|Y_{train}, X_{train})dw} $$\n",
    "\n",
    "tenemos que $p(y|X, w)$ es una red neuronal que dado unos datos $X$ y los pesos $w$ de la red neuronal predecimos $y$ es decir la probabilidad de posteriori de y (una distribucion de probabilidad).\n",
    "\n",
    "Lo que observamos con esta forma de ver los pesos de la red neuronal es que podemos ver una distribucion de los pesos $p(w|Y_{train}, X_{train})$ a partir de los datos de entrenamiento y podemos cuantificar la incertidumbre de estos pesos.\n",
    "\n",
    "En el ejemplo que ponemos lo que queremos conseguir es el valor esperado de la distribucion de pesos sobre las prediciones sobre y:\n",
    "$$\\mathbb{E}_{p(w|X_{train}, Y_{train})} p(y|X, w) $$\n",
    "donde:\n",
    "$$p(w|X_{train}, Y_{train}) = \\frac{p(Y_{train}|X_{train}, w).p(w)}{Z}$$\n",
    "donde $Z$ es un valor de normalizacion para que la probabilidad tenga como valor maximo 1, el problema es que esta normalizacion es dificultosa de calcular, tenemos que calcularla para todos los valores de $w$ y eso es bastante dificil.\n",
    "\n",
    "Aqui es donde entra el juego MCMC y su forma de aproximarse a la distribucion a posteriori de una manera rapida y sin inferencias de los parametros exactas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}